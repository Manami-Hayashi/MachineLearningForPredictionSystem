{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import the necessary libraries and set the working directory",
   "id": "9da397606a210e59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:32:34.617803Z",
     "start_time": "2024-10-25T10:31:44.672300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import graphviz\n",
    "import joblib\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(r'D:\\KDG\\2024-2025\\Semester 1\\DAI5\\GroupProject\\SatisfactionLevel0\\Resources')\n",
    "\n",
    "missing_values = ['n/a', 'na', 'nan', 'N/A', 'NA', 'NaN', 'NAN', '--', 'Missing']\n",
    "df = pd.read_csv('cleaned_employees.csv', na_values=missing_values, sep=',', decimal='.')\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # to see all the columns\n",
    "print(df.head())\n",
    "print(df.info())"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      EmpID  Gender       Age MaritalStatus        JobLevel  Experience  \\\n",
      "0 -1.727136    Male -0.363508       Married             Mid   -0.294224   \n",
      "1 -1.721410  Female -0.167125       Married             Mid    0.411979   \n",
      "2 -1.696216  Female -1.247231        Single  Intern/Fresher   -1.141666   \n",
      "3 -1.711104  Female -0.658082       Married          Junior   -0.435464   \n",
      "4 -1.701942   Other -1.247231        Single          Junior   -1.141666   \n",
      "\n",
      "        Dept    EmpType  PhysicalActivityHours  Workload  Stress  SleepHours  \\\n",
      "0         IT  Full-Time               0.494266         2       1    0.602432   \n",
      "1    Finance  Full-Time              -0.234700         2       2    0.907144   \n",
      "2  Marketing  Full-Time               0.077714         5       4   -0.514846   \n",
      "3         IT   Contract              -0.130562         3       1    0.500862   \n",
      "4      Sales  Part-Time               1.743922         2       1   -2.139977   \n",
      "\n",
      "        CommuteMode  CommuteDistance  TeamSize  NumReports  haveOT  \\\n",
      "0               Car         0.776845 -0.676992   -0.777458    True   \n",
      "1               Car         0.180903 -0.827518   -0.777458   False   \n",
      "2         Motorbike         0.419280  2.032478   -0.777458    True   \n",
      "3  Public Transport        -0.057474 -1.128570   -0.777458    True   \n",
      "4               Car         0.776845 -1.429623   -0.777458   False   \n",
      "\n",
      "   TrainingHoursPerYear  JobSatisfaction  \n",
      "0             -0.276509                5  \n",
      "1             -0.092427                5  \n",
      "2             -1.970063                5  \n",
      "3             -1.049653                5  \n",
      "4             -1.233735                5  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3007 entries, 0 to 3006\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   EmpID                  3007 non-null   float64\n",
      " 1   Gender                 3007 non-null   object \n",
      " 2   Age                    3007 non-null   float64\n",
      " 3   MaritalStatus          3007 non-null   object \n",
      " 4   JobLevel               3007 non-null   object \n",
      " 5   Experience             3007 non-null   float64\n",
      " 6   Dept                   3007 non-null   object \n",
      " 7   EmpType                3007 non-null   object \n",
      " 8   PhysicalActivityHours  3007 non-null   float64\n",
      " 9   Workload               3007 non-null   int64  \n",
      " 10  Stress                 3007 non-null   int64  \n",
      " 11  SleepHours             3007 non-null   float64\n",
      " 12  CommuteMode            3007 non-null   object \n",
      " 13  CommuteDistance        3007 non-null   float64\n",
      " 14  TeamSize               3007 non-null   float64\n",
      " 15  NumReports             3007 non-null   float64\n",
      " 16  haveOT                 3007 non-null   bool   \n",
      " 17  TrainingHoursPerYear   3007 non-null   float64\n",
      " 18  JobSatisfaction        3007 non-null   int64  \n",
      "dtypes: bool(1), float64(9), int64(3), object(6)\n",
      "memory usage: 425.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert the object variables to categories",
   "id": "886d0fde0caae453"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:32:34.802869Z",
     "start_time": "2024-10-25T10:32:34.632950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['Gender'] = df['Gender'].astype(pd.CategoricalDtype(categories=df['Gender'].unique()))\n",
    "df['MaritalStatus'] = df['MaritalStatus'].astype(pd.CategoricalDtype(categories=df['MaritalStatus'].unique()))\n",
    "df['Dept'] = df['Dept'].astype(pd.CategoricalDtype(categories=df['Dept'].unique()))\n",
    "df['EmpType'] = df['EmpType'].astype(pd.CategoricalDtype(categories=df['EmpType'].unique()))\n",
    "df['CommuteMode'] = df['CommuteMode'].astype(pd.CategoricalDtype(categories=df['CommuteMode'].unique()))\n",
    "df['haveOT'] = df['haveOT'].astype(pd.CategoricalDtype(categories=df['haveOT'].unique()))\n",
    "\n",
    "df['JobLevel'] = df['JobLevel'].astype(\n",
    "    pd.CategoricalDtype(categories=['Intern/Fresher', 'Junior', 'Mid', 'Senior', 'Lead'], ordered=True))\n",
    "\n",
    "df['Workload'] = df['Workload'].astype(\n",
    "    pd.CategoricalDtype(categories=[1, 2, 3, 4, 5], ordered=True))\n",
    "\n",
    "df['Stress'] = df['Stress'].astype(\n",
    "    pd.CategoricalDtype(categories=[1, 2, 3, 4, 5], ordered=True))\n",
    "\n",
    "df['JobSatisfaction'] = df['JobSatisfaction'].astype(\n",
    "    pd.CategoricalDtype(categories=[1, 2, 3, 4, 5], ordered=True))\n",
    "\n",
    "print(df.info())\n"
   ],
   "id": "1ee417e3666333f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3007 entries, 0 to 3006\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   EmpID                  3007 non-null   float64 \n",
      " 1   Gender                 3007 non-null   category\n",
      " 2   Age                    3007 non-null   float64 \n",
      " 3   MaritalStatus          3007 non-null   category\n",
      " 4   JobLevel               3007 non-null   category\n",
      " 5   Experience             3007 non-null   float64 \n",
      " 6   Dept                   3007 non-null   category\n",
      " 7   EmpType                3007 non-null   category\n",
      " 8   PhysicalActivityHours  3007 non-null   float64 \n",
      " 9   Workload               3007 non-null   category\n",
      " 10  Stress                 3007 non-null   category\n",
      " 11  SleepHours             3007 non-null   float64 \n",
      " 12  CommuteMode            3007 non-null   category\n",
      " 13  CommuteDistance        3007 non-null   float64 \n",
      " 14  TeamSize               3007 non-null   float64 \n",
      " 15  NumReports             3007 non-null   float64 \n",
      " 16  haveOT                 3007 non-null   category\n",
      " 17  TrainingHoursPerYear   3007 non-null   float64 \n",
      " 18  JobSatisfaction        3007 non-null   category\n",
      "dtypes: category(10), float64(9)\n",
      "memory usage: 242.8 KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Select the relevant features and target variable",
   "id": "392c10ca45c09230"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:32:34.864441Z",
     "start_time": "2024-10-25T10:32:34.819464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select the relevant features and target\n",
    "X = df[['Workload', 'SleepHours', 'Stress']]\n",
    "y = df['JobSatisfaction']"
   ],
   "id": "102e503596f5f658",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split the dataset into train, test and validation",
   "id": "9068f0f0750521c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "random_state is a parameter that controls the randomness of the data splitting process. It ensures that the train-test split or any other randomized operation will yield reproducible results.\n",
    "\n",
    "  Why it's used: Without random_state, every time you run the code, the dataset will be split differently. By setting random_state to a specific integer (like 42), the split will always be the same each time the code is executed, which is useful for debugging, sharing experiments, or comparing results.\n",
    "    Why 42?: It's just a common convention in data science (a reference to The Hitchhiker's Guide to the Galaxy), but any fixed number can be used."
   ],
   "id": "6ac5a8256f58965b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:32:34.942003Z",
     "start_time": "2024-10-25T10:32:34.886159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train-test-validation split (60% train, 20% validation, 20% test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)"
   ],
   "id": "435fa13092843966",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Apply the Decision Tree model",
   "id": "eb169f867ad1a5ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:32:34.972994Z",
     "start_time": "2024-10-25T10:32:34.952613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)"
   ],
   "id": "6234213d03a9f810",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "max_deph: Limits how deep the tree can grow. A deeper tree can fit more complex patterns, but it may also fit noise in the training data, leading to overfitting.\n",
    "\n",
    "min_samples_split: Determines the minimum number of samples required to split an internal node. A higher value can reduce overfitting by preventing splits that create nodes with very few samples.\n",
    "\n",
    "min_samples_leaf: Sets the minimum number of samples that must be present in a leaf node. Increasing this number helps smooth the model and reduce overfitting."
   ],
   "id": "88dd7721a6228021"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:32:35.019057Z",
     "start_time": "2024-10-25T10:32:34.987191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameter tuning for DecisionTreeClassifier using GridSearchCV\n",
    "param_grid_dt = {\n",
    "    'max_depth': [1, 2, 3, 5, 10, 50, 100, None],\n",
    "    'min_samples_split': [1, 2, 5, 10, 11, 12, 13, 14, 15, 50],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 10, 50, 100]\n",
    "}"
   ],
   "id": "5a0159172198677a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "GridSearchCV: This method performs an exhaustive search over the specified hyperparameter values in param_grid_dt. It trains a new model for every combination of hyperparameters.\n",
    "\n",
    " cv=5: This means that 5-fold cross-validation is used, where the training set is divided into 5 subsets. The model is trained on 4 of the subsets and tested on the remaining subset. This process is repeated 5 times, with each subset serving as the test set once. This helps in assessing the model's performance more reliably.\n",
    "\n",
    "n_jobs=-1: This parameter tells GridSearchCV to use all available processors to perform the computations in parallel, speeding up the tuning process.\n",
    "\n",
    "verbose=1: This controls the verbosity of the output during the fitting process. A value of 1 will provide basic updates on the progress.\n",
    "\n",
    "\n",
    "### What Happens Behind the Scenes?\n",
    "\n",
    "   Cross-Validation: For each combination of hyperparameters, the training data is split into different folds (e.g., 5 folds). The model is trained on a subset of these folds and validated on the remaining fold. This process is repeated for each fold, and the results are averaged.\n",
    "\n",
    "   Performance Metrics: After training and validation, the mean performance (like MSE) is calculated for each hyperparameter set.\n",
    "\n",
    "   Final Model: After identifying the best combination of hyperparameters, the best_estimator_ is created with those parameters and is used for predictions on the test set."
   ],
   "id": "b42d898e98c5a372"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:33:23.494851Z",
     "start_time": "2024-10-25T10:32:35.031624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GridSearchCV for DecisionTreeRegressor\n",
    "grid_search_dt = GridSearchCV(estimator=dt_clf, param_grid=param_grid_dt, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters after tuning\n",
    "print(\"Best Parameters for Decision Tree Classifier:\")\n",
    "print(grid_search_dt.best_params_)"
   ],
   "id": "aeefd09bd52292e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 560 candidates, totalling 2800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PythonEnv\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "280 fits failed out of a total of 2800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "280 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\PythonEnv\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\PythonEnv\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"D:\\PythonEnv\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"D:\\PythonEnv\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\PythonEnv\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586\n",
      " 0.41153586 0.41153586 0.41153586 0.41153586        nan 0.41153586\n",
      " 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586\n",
      " 0.41153586 0.41153586        nan 0.41153586 0.41153586 0.41153586\n",
      " 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586\n",
      "        nan 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586\n",
      " 0.41153586 0.41153586 0.41153586 0.41153586        nan 0.41153586\n",
      " 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586\n",
      " 0.41153586 0.41153586        nan 0.41153586 0.41153586 0.41153586\n",
      " 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586\n",
      "        nan 0.41153586 0.41153586 0.41153586 0.41153586 0.41153586\n",
      " 0.41153586 0.41153586 0.41153586 0.41153586        nan 0.43150046\n",
      " 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046\n",
      " 0.43150046 0.43150046        nan 0.43150046 0.43150046 0.43150046\n",
      " 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046\n",
      "        nan 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046\n",
      " 0.43150046 0.43150046 0.43150046 0.43150046        nan 0.43150046\n",
      " 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046\n",
      " 0.43150046 0.43150046        nan 0.43150046 0.43150046 0.43150046\n",
      " 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046\n",
      "        nan 0.43150046 0.43150046 0.43150046 0.43150046 0.43150046\n",
      " 0.43150046 0.43150046 0.43150046 0.43150046        nan 0.43482456\n",
      " 0.43482456 0.43482456 0.43482456 0.43482456 0.43482456 0.43482456\n",
      " 0.43482456 0.43482456        nan 0.43704217 0.43704217 0.43704217\n",
      " 0.43704217 0.43704217 0.43704217 0.43704217 0.43704217 0.43704217\n",
      "        nan 0.43704217 0.43704217 0.43704217 0.43704217 0.43704217\n",
      " 0.43704217 0.43704217 0.43704217 0.43704217        nan 0.43704217\n",
      " 0.43704217 0.43704217 0.43704217 0.43704217 0.43704217 0.43704217\n",
      " 0.43704217 0.43704217        nan 0.43704217 0.43704217 0.43704217\n",
      " 0.43704217 0.43704217 0.43704217 0.43704217 0.43704217 0.43704217\n",
      "        nan 0.43704217 0.43704217 0.43704217 0.43704217 0.43704217\n",
      " 0.43704217 0.43704217 0.43704217 0.43704217        nan 0.43371191\n",
      " 0.43371191 0.43371191 0.43371191 0.43371191 0.43371191 0.43371191\n",
      " 0.43371191 0.43371191        nan 0.43482456 0.43482456 0.43482456\n",
      " 0.43482456 0.43482456 0.43482456 0.43482456 0.43482456 0.43482456\n",
      "        nan 0.43538012 0.43538012 0.43593413 0.43648815 0.43648815\n",
      " 0.43648815 0.43648815 0.43648815 0.43315943        nan 0.43593413\n",
      " 0.43593413 0.43593413 0.43648815 0.43648815 0.43648815 0.43648815\n",
      " 0.43648815 0.43315943        nan 0.43704678 0.43704678 0.4376008\n",
      " 0.43815482 0.43815482 0.43815482 0.43815482 0.43815482 0.43315943\n",
      "        nan 0.43593413 0.43593413 0.43593413 0.43648815 0.43648815\n",
      " 0.43648815 0.43648815 0.43648815 0.43315943        nan 0.43038781\n",
      " 0.43038781 0.43038781 0.43038781 0.43038781 0.43038781 0.43038781\n",
      " 0.43038781 0.42705756        nan 0.43427362 0.43427362 0.43427362\n",
      " 0.43427362 0.43427362 0.43427362 0.43427362 0.43427362 0.43427362\n",
      "        nan 0.43316097 0.43316097 0.43316097 0.43316097 0.43316097\n",
      " 0.43316097 0.43316097 0.43316097 0.43316097        nan 0.38211911\n",
      " 0.37823946 0.38822561 0.38600492 0.39044167 0.38933826 0.38823022\n",
      " 0.39433364 0.40709911        nan 0.38878424 0.38656048 0.38878578\n",
      " 0.38711604 0.3898892  0.38822869 0.39211604 0.39766544 0.40765312\n",
      "        nan 0.37989997 0.37989997 0.38490305 0.38545399 0.38545706\n",
      " 0.3860157  0.38435211 0.39045399 0.40654509        nan 0.37269775\n",
      " 0.37269775 0.37492151 0.37713912 0.37824869 0.38047091 0.38047091\n",
      " 0.38823792 0.40543398        nan 0.40154201 0.40154201 0.40154201\n",
      " 0.40154201 0.40154201 0.40154201 0.40154201 0.40154201 0.40709295\n",
      "        nan 0.43427362 0.43427362 0.43427362 0.43427362 0.43427362\n",
      " 0.43427362 0.43427362 0.43427362 0.43427362        nan 0.43316097\n",
      " 0.43316097 0.43316097 0.43316097 0.43316097 0.43316097 0.43316097\n",
      " 0.43316097 0.43316097        nan 0.33388273 0.33388427 0.35441059\n",
      " 0.35274238 0.3610634  0.36328409 0.3610634  0.3671699  0.40044937\n",
      "        nan 0.34553401 0.33998923 0.35052785 0.35163281 0.35995537\n",
      " 0.35995845 0.36272853 0.3699446  0.40211142        nan 0.34164666\n",
      " 0.34164666 0.35108033 0.35274238 0.35829024 0.36051093 0.36106802\n",
      " 0.36606033 0.40100339        nan 0.34608033 0.34608033 0.35218221\n",
      " 0.35551247 0.35717759 0.36106187 0.36161742 0.37215913 0.40210988\n",
      "        nan 0.39765312 0.39765312 0.39765312 0.39765312 0.39765312\n",
      " 0.39765312 0.39765312 0.39765312 0.40709295        nan 0.43427362\n",
      " 0.43427362 0.43427362 0.43427362 0.43427362 0.43427362 0.43427362\n",
      " 0.43427362 0.43427362        nan 0.43316097 0.43316097 0.43316097\n",
      " 0.43316097 0.43316097 0.43316097 0.43316097 0.43316097 0.43316097\n",
      "        nan 0.33388273 0.33388427 0.35441059 0.35274238 0.3610634\n",
      " 0.36328409 0.3610634  0.3671699  0.40044937        nan 0.34553401\n",
      " 0.33998923 0.35052785 0.35163281 0.35995537 0.35995845 0.36272853\n",
      " 0.3699446  0.40211142        nan 0.34164666 0.34164666 0.35108033\n",
      " 0.35274238 0.35829024 0.36051093 0.36106802 0.36606033 0.40100339\n",
      "        nan 0.34608033 0.34608033 0.35218221 0.35551247 0.35717759\n",
      " 0.36106187 0.36161742 0.37215913 0.40210988        nan 0.39765312\n",
      " 0.39765312 0.39765312 0.39765312 0.39765312 0.39765312 0.39765312\n",
      " 0.39765312 0.40709295        nan 0.43427362 0.43427362 0.43427362\n",
      " 0.43427362 0.43427362 0.43427362 0.43427362 0.43427362 0.43427362\n",
      "        nan 0.43316097 0.43316097 0.43316097 0.43316097 0.43316097\n",
      " 0.43316097 0.43316097 0.43316097 0.43316097        nan 0.33388273\n",
      " 0.33388427 0.35441059 0.35274238 0.3610634  0.36328409 0.3610634\n",
      " 0.3671699  0.40044937        nan 0.34553401 0.33998923 0.35052785\n",
      " 0.35163281 0.35995537 0.35995845 0.36272853 0.3699446  0.40211142\n",
      "        nan 0.34164666 0.34164666 0.35108033 0.35274238 0.35829024\n",
      " 0.36051093 0.36106802 0.36606033 0.40100339        nan 0.34608033\n",
      " 0.34608033 0.35218221 0.35551247 0.35717759 0.36106187 0.36161742\n",
      " 0.37215913 0.40210988        nan 0.39765312 0.39765312 0.39765312\n",
      " 0.39765312 0.39765312 0.39765312 0.39765312 0.39765312 0.40709295\n",
      "        nan 0.43427362 0.43427362 0.43427362 0.43427362 0.43427362\n",
      " 0.43427362 0.43427362 0.43427362 0.43427362        nan 0.43316097\n",
      " 0.43316097 0.43316097 0.43316097 0.43316097 0.43316097 0.43316097\n",
      " 0.43316097 0.43316097]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Decision Tree Classifier:\n",
      "{'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 11}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate on validation set",
   "id": "a835b5e410f5c976"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:33:23.758082Z",
     "start_time": "2024-10-25T10:33:23.507434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_val_pred_dt = grid_search_dt.predict(X_val)\n",
    "val_acc_dt = accuracy_score(y_val, y_val_pred_dt)\n",
    "print(f\"Validation Accuracy (Decision Tree): {val_acc_dt}\")\n",
    "# Setting zero_division=0 will replace undefined metrics with 0 instead of issuing a warning.\n",
    "print(classification_report(y_val, y_val_pred_dt, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_val_pred_dt))\n",
    "\n",
    "# Best Decision Tree model\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "\n",
    "# Save the best decision tree model to a file\n",
    "joblib.dump(best_dt, 'decision_tree_model.pkl')\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_test_pred_dt = best_dt.predict(X_test)\n",
    "test_acc_dt = accuracy_score(y_test, y_test_pred_dt)\n",
    "print(f\"Test Accuracy (Decision Tree): {test_acc_dt}\")\n",
    "# Setting zero_division=0 will replace undefined metrics with 0 instead of issuing a warning.\n",
    "print(classification_report(y_test, y_test_pred_dt, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_test_pred_dt))"
   ],
   "id": "e47124483cfc5b40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (Decision Tree): 0.4219269102990033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.30      0.36        82\n",
      "           2       0.10      0.02      0.03        50\n",
      "           3       0.25      0.08      0.12       120\n",
      "           4       0.44      0.88      0.59       244\n",
      "           5       0.25      0.04      0.07       106\n",
      "\n",
      "    accuracy                           0.42       602\n",
      "   macro avg       0.30      0.26      0.24       602\n",
      "weighted avg       0.34      0.42      0.33       602\n",
      "\n",
      "[[ 25   1   9  45   2]\n",
      " [  1   1   4  43   1]\n",
      " [ 18   2  10  88   2]\n",
      " [  8   4  11 214   7]\n",
      " [  3   2   6  91   4]]\n",
      "Test Accuracy (Decision Tree): 0.43853820598006643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.28      0.33        80\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.29      0.09      0.14       100\n",
      "           4       0.46      0.88      0.61       256\n",
      "           5       0.42      0.08      0.13       106\n",
      "\n",
      "    accuracy                           0.44       602\n",
      "   macro avg       0.32      0.26      0.24       602\n",
      "weighted avg       0.37      0.44      0.35       602\n",
      "\n",
      "[[ 22   2   9  46   1]\n",
      " [  2   0   2  54   2]\n",
      " [ 13   4   9  73   1]\n",
      " [ 12   3   9 225   7]\n",
      " [  5   4   2  87   8]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize the decision tree",
   "id": "e5474a8562b90252"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T10:33:38.641543Z",
     "start_time": "2024-10-25T10:33:23.769133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Export the tree to dot format\n",
    "dot_data = export_graphviz(best_dt, out_file=None,\n",
    "                           feature_names=X.columns,\n",
    "                           filled=True, rounded=True,\n",
    "                           special_characters=True)\n",
    "\n",
    "# Create a graph from the dot data\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\")\n",
    "graph.view()  # This will open the visualized tree in your default viewer\n"
   ],
   "id": "ae9ebb06c7392db3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_tree.pdf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
