{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import the necessary libraries and set the working directory",
   "id": "9da397606a210e59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:46:43.551408Z",
     "start_time": "2024-10-18T10:46:43.466710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import graphviz\n",
    "import joblib\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(r'C:\\Users\\mnmhy\\IntelliJprojects\\DAI5\\Resources')\n",
    "\n",
    "missing_values = ['n/a', 'na', 'nan', 'N/A', 'NA', 'NaN', 'NAN', '--', 'Missing']\n",
    "df = pd.read_csv('cleaned_employees.csv', na_values=missing_values, sep=',', decimal='.')\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # to see all the columns\n",
    "print(df.head())\n",
    "print(df.info())"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      EmpID  Gender       Age MaritalStatus        JobLevel  Experience  \\\n",
      "0 -1.727136    Male -0.363508       Married             Mid   -0.294224   \n",
      "1 -1.721410  Female -0.167125       Married             Mid    0.411979   \n",
      "2 -1.696216  Female -1.247231        Single  Intern/Fresher   -1.141666   \n",
      "3 -1.711104  Female -0.658082       Married          Junior   -0.435464   \n",
      "4 -1.701942   Other -1.247231        Single          Junior   -1.141666   \n",
      "\n",
      "        Dept    EmpType  PhysicalActivityHours  Workload  Stress  SleepHours  \\\n",
      "0         IT  Full-Time               0.494266         2       1    0.602432   \n",
      "1    Finance  Full-Time              -0.234700         2       2    0.907144   \n",
      "2  Marketing  Full-Time               0.077714         5       4   -0.514846   \n",
      "3         IT   Contract              -0.130562         3       1    0.500862   \n",
      "4      Sales  Part-Time               1.743922         2       1   -2.139977   \n",
      "\n",
      "        CommuteMode  CommuteDistance  TeamSize  NumReports  haveOT  \\\n",
      "0               Car         0.776845 -0.676992   -0.777458    True   \n",
      "1               Car         0.180903 -0.827518   -0.777458   False   \n",
      "2         Motorbike         0.419280  2.032478   -0.777458    True   \n",
      "3  Public Transport        -0.057474 -1.128570   -0.777458    True   \n",
      "4               Car         0.776845 -1.429623   -0.777458   False   \n",
      "\n",
      "   TrainingHoursPerYear  JobSatisfaction  \n",
      "0             -0.276509                5  \n",
      "1             -0.092427                5  \n",
      "2             -1.970063                5  \n",
      "3             -1.049653                5  \n",
      "4             -1.233735                5  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3007 entries, 0 to 3006\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   EmpID                  3007 non-null   float64\n",
      " 1   Gender                 3007 non-null   object \n",
      " 2   Age                    3007 non-null   float64\n",
      " 3   MaritalStatus          3007 non-null   object \n",
      " 4   JobLevel               3007 non-null   object \n",
      " 5   Experience             3007 non-null   float64\n",
      " 6   Dept                   3007 non-null   object \n",
      " 7   EmpType                3007 non-null   object \n",
      " 8   PhysicalActivityHours  3007 non-null   float64\n",
      " 9   Workload               3007 non-null   int64  \n",
      " 10  Stress                 3007 non-null   int64  \n",
      " 11  SleepHours             3007 non-null   float64\n",
      " 12  CommuteMode            3007 non-null   object \n",
      " 13  CommuteDistance        3007 non-null   float64\n",
      " 14  TeamSize               3007 non-null   float64\n",
      " 15  NumReports             3007 non-null   float64\n",
      " 16  haveOT                 3007 non-null   bool   \n",
      " 17  TrainingHoursPerYear   3007 non-null   float64\n",
      " 18  JobSatisfaction        3007 non-null   int64  \n",
      "dtypes: bool(1), float64(9), int64(3), object(6)\n",
      "memory usage: 425.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert the object variables to categories",
   "id": "886d0fde0caae453"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:46:43.899744Z",
     "start_time": "2024-10-18T10:46:43.824053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['Gender'] = df['Gender'].astype(pd.CategoricalDtype(categories=df['Gender'].unique()))\n",
    "df['MaritalStatus'] = df['MaritalStatus'].astype(pd.CategoricalDtype(categories=df['MaritalStatus'].unique()))\n",
    "df['Dept'] = df['Dept'].astype(pd.CategoricalDtype(categories=df['Dept'].unique()))\n",
    "df['EmpType'] = df['EmpType'].astype(pd.CategoricalDtype(categories=df['EmpType'].unique()))\n",
    "df['CommuteMode'] = df['CommuteMode'].astype(pd.CategoricalDtype(categories=df['CommuteMode'].unique()))\n",
    "df['haveOT'] = df['haveOT'].astype(pd.CategoricalDtype(categories=df['haveOT'].unique()))\n",
    "\n",
    "df['JobLevel'] = df['JobLevel'].astype(\n",
    "    pd.CategoricalDtype(categories=['Intern/Fresher', 'Junior', 'Mid', 'Senior', 'Lead'], ordered=True))\n",
    "\n",
    "df['Workload'] = df['Workload'].astype(\n",
    "    pd.CategoricalDtype(categories=[1, 2, 3, 4, 5], ordered=True))\n",
    "\n",
    "df['Stress'] = df['Stress'].astype(\n",
    "    pd.CategoricalDtype(categories=[1, 2, 3, 4, 5], ordered=True))\n",
    "\n",
    "df['JobSatisfaction'] = df['JobSatisfaction'].astype(\n",
    "    pd.CategoricalDtype(categories=[1, 2, 3, 4, 5], ordered=True))\n",
    "\n",
    "print(df.info())\n"
   ],
   "id": "1ee417e3666333f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3007 entries, 0 to 3006\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   EmpID                  3007 non-null   float64 \n",
      " 1   Gender                 3007 non-null   category\n",
      " 2   Age                    3007 non-null   float64 \n",
      " 3   MaritalStatus          3007 non-null   category\n",
      " 4   JobLevel               3007 non-null   category\n",
      " 5   Experience             3007 non-null   float64 \n",
      " 6   Dept                   3007 non-null   category\n",
      " 7   EmpType                3007 non-null   category\n",
      " 8   PhysicalActivityHours  3007 non-null   float64 \n",
      " 9   Workload               3007 non-null   category\n",
      " 10  Stress                 3007 non-null   category\n",
      " 11  SleepHours             3007 non-null   float64 \n",
      " 12  CommuteMode            3007 non-null   category\n",
      " 13  CommuteDistance        3007 non-null   float64 \n",
      " 14  TeamSize               3007 non-null   float64 \n",
      " 15  NumReports             3007 non-null   float64 \n",
      " 16  haveOT                 3007 non-null   category\n",
      " 17  TrainingHoursPerYear   3007 non-null   float64 \n",
      " 18  JobSatisfaction        3007 non-null   category\n",
      "dtypes: category(10), float64(9)\n",
      "memory usage: 242.8 KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Select the relevant features and target variable",
   "id": "392c10ca45c09230"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:46:44.027010Z",
     "start_time": "2024-10-18T10:46:44.015465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select the relevant features and target\n",
    "X = df[['Workload', 'SleepHours', 'Stress']]\n",
    "y = df['JobSatisfaction']"
   ],
   "id": "102e503596f5f658",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split the dataset into train, test and validation",
   "id": "9068f0f0750521c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "random_state is a parameter that controls the randomness of the data splitting process. It ensures that the train-test split or any other randomized operation will yield reproducible results.\n",
    "\n",
    "  Why it's used: Without random_state, every time you run the code, the dataset will be split differently. By setting random_state to a specific integer (like 42), the split will always be the same each time the code is executed, which is useful for debugging, sharing experiments, or comparing results.\n",
    "    Why 42?: It's just a common convention in data science (a reference to The Hitchhiker's Guide to the Galaxy), but any fixed number can be used."
   ],
   "id": "6ac5a8256f58965b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:46:44.152480Z",
     "start_time": "2024-10-18T10:46:44.129922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train-test-validation split (60% train, 20% validation, 20% test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)"
   ],
   "id": "435fa13092843966",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Apply the Decision Tree model",
   "id": "eb169f867ad1a5ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:46:44.308361Z",
     "start_time": "2024-10-18T10:46:44.267274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)"
   ],
   "id": "6234213d03a9f810",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "max_deph: Limits how deep the tree can grow. A deeper tree can fit more complex patterns, but it may also fit noise in the training data, leading to overfitting.\n",
    "\n",
    "min_samples_split: Determines the minimum number of samples required to split an internal node. A higher value can reduce overfitting by preventing splits that create nodes with very few samples.\n",
    "\n",
    "min_samples_leaf: Sets the minimum number of samples that must be present in a leaf node. Increasing this number helps smooth the model and reduce overfitting."
   ],
   "id": "88dd7721a6228021"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:46:44.448713Z",
     "start_time": "2024-10-18T10:46:44.423593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameter tuning for DecisionTreeClassifier using GridSearchCV\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ],
   "id": "5a0159172198677a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "GridSearchCV: This method performs an exhaustive search over the specified hyperparameter values in param_grid_dt. It trains a new model for every combination of hyperparameters.\n",
    "\n",
    " cv=5: This means that 5-fold cross-validation is used, where the training set is divided into 5 subsets. The model is trained on 4 of the subsets and tested on the remaining subset. This process is repeated 5 times, with each subset serving as the test set once. This helps in assessing the model's performance more reliably.\n",
    "\n",
    "n_jobs=-1: This parameter tells GridSearchCV to use all available processors to perform the computations in parallel, speeding up the tuning process.\n",
    "\n",
    "verbose=1: This controls the verbosity of the output during the fitting process. A value of 1 will provide basic updates on the progress.\n",
    "\n",
    "\n",
    "### What Happens Behind the Scenes?\n",
    "\n",
    "   Cross-Validation: For each combination of hyperparameters, the training data is split into different folds (e.g., 5 folds). The model is trained on a subset of these folds and validated on the remaining fold. This process is repeated for each fold, and the results are averaged.\n",
    "\n",
    "   Performance Metrics: After training and validation, the mean performance (like MSE) is calculated for each hyperparameter set.\n",
    "\n",
    "   Final Model: After identifying the best combination of hyperparameters, the best_estimator_ is created with those parameters and is used for predictions on the test set."
   ],
   "id": "b42d898e98c5a372"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:46:56.904769Z",
     "start_time": "2024-10-18T10:46:44.568823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GridSearchCV for DecisionTreeRegressor\n",
    "grid_search_dt = GridSearchCV(estimator=dt_clf, param_grid=param_grid_dt, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_dt.fit(X_train, y_train)"
   ],
   "id": "aeefd09bd52292e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 5, 10, None],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             verbose=1)"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 5, 10, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 5, 10, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate on validation set",
   "id": "a835b5e410f5c976"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:46:57.141842Z",
     "start_time": "2024-10-18T10:46:57.053275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_val_pred_dt = grid_search_dt.predict(X_val)\n",
    "val_acc_dt = accuracy_score(y_val, y_val_pred_dt)\n",
    "print(f\"Validation Accuracy (Decision Tree): {val_acc_dt}\")\n",
    "# Setting zero_division=0 will replace undefined metrics with 0 instead of issuing a warning.\n",
    "print(classification_report(y_val, y_val_pred_dt,zero_division=0))\n",
    "print(confusion_matrix(y_val, y_val_pred_dt))\n",
    "\n",
    "# Best Decision Tree model\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "\n",
    "# Save the best decision tree model to a file\n",
    "joblib.dump(best_dt, 'decision_tree_model.pkl')\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_test_pred_dt = best_dt.predict(X_test)\n",
    "test_acc_dt = accuracy_score(y_test, y_test_pred_dt)\n",
    "print(f\"Test Accuracy (Decision Tree): {test_acc_dt}\")\n",
    "# Setting zero_division=0 will replace undefined metrics with 0 instead of issuing a warning.\n",
    "print(classification_report(y_test, y_test_pred_dt,zero_division=0))\n",
    "print(confusion_matrix(y_test, y_test_pred_dt))"
   ],
   "id": "e47124483cfc5b40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (Decision Tree): 0.4152823920265781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.15      0.20        82\n",
      "           2       0.00      0.00      0.00        50\n",
      "           3       0.25      0.09      0.13       120\n",
      "           4       0.44      0.93      0.60       244\n",
      "           5       0.00      0.00      0.00       106\n",
      "\n",
      "    accuracy                           0.42       602\n",
      "   macro avg       0.20      0.23      0.19       602\n",
      "weighted avg       0.27      0.42      0.29       602\n",
      "\n",
      "[[ 12   0  19  51   0]\n",
      " [  1   0   2  47   0]\n",
      " [ 12   0  11  97   0]\n",
      " [ 11   0   6 227   0]\n",
      " [  3   0   6  97   0]]\n",
      "Test Accuracy (Decision Tree): 0.4269102990033223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.11      0.16        80\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.24      0.10      0.14       100\n",
      "           4       0.45      0.93      0.61       256\n",
      "           5       0.00      0.00      0.00       106\n",
      "\n",
      "    accuracy                           0.43       602\n",
      "   macro avg       0.19      0.23      0.18       602\n",
      "weighted avg       0.27      0.43      0.30       602\n",
      "\n",
      "[[  9   0  19  52   0]\n",
      " [  1   0   1  58   0]\n",
      " [ 10   0  10  80   0]\n",
      " [ 10   0   8 238   0]\n",
      " [  5   0   4  97   0]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize the decision tree",
   "id": "e5474a8562b90252"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:47:00.059724Z",
     "start_time": "2024-10-18T10:46:57.328205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Export the tree to dot format\n",
    "dot_data = export_graphviz(best_dt, out_file=None, \n",
    "                           feature_names=X.columns,  \n",
    "                           filled=True, rounded=True,  \n",
    "                           special_characters=True)  \n",
    "\n",
    "# Create a graph from the dot data\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"decision_tree\") \n",
    "graph.view()  # This will open the visualized tree in your default viewer\n"
   ],
   "id": "ae9ebb06c7392db3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_tree.pdf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Apply Random Forest Classifier to improve performance",
   "id": "ccee69bd0fdc9a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:49:02.803118Z",
     "start_time": "2024-10-18T10:47:00.254305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for RandomForestClassifier\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# GridSearchCV for RandomForestClassifier\n",
    "grid_search_rf = GridSearchCV(estimator=rf_clf, param_grid=param_grid_rf, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred_rf = grid_search_rf.predict(X_val)\n",
    "val_acc_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "print(f\"Validation Accuracy (Random Forest): {val_acc_rf}\")\n",
    "# Setting zero_division=0 will replace undefined metrics with 0 instead of issuing a warning.\n",
    "print(classification_report(y_val, y_val_pred_rf,zero_division=0))\n",
    "print(confusion_matrix(y_val, y_val_pred_rf))\n",
    "\n",
    "# Best RandomForest model\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_test_pred_rf = best_rf.predict(X_test)\n",
    "test_acc_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "print(f\"Test Accuracy (Random Forest): {test_acc_rf}\")\n",
    "# Setting zero_division=0 will replace undefined metrics with 0 instead of issuing a warning.\n",
    "print(classification_report(y_test, y_test_pred_rf,zero_division=0))\n",
    "print(confusion_matrix(y_test, y_test_pred_rf))"
   ],
   "id": "1b5551d35f16433c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Validation Accuracy (Random Forest): 0.4318936877076412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.23      0.32        82\n",
      "           2       0.00      0.00      0.00        50\n",
      "           3       0.20      0.01      0.02       120\n",
      "           4       0.43      0.98      0.60       244\n",
      "           5       0.00      0.00      0.00       106\n",
      "\n",
      "    accuracy                           0.43       602\n",
      "   macro avg       0.23      0.24      0.19       602\n",
      "weighted avg       0.29      0.43      0.29       602\n",
      "\n",
      "[[ 19   0   0  63   0]\n",
      " [  1   0   0  49   0]\n",
      " [ 12   0   1 107   0]\n",
      " [  2   0   2 240   0]\n",
      " [  1   0   2 103   0]]\n",
      "Test Accuracy (Random Forest): 0.43521594684385384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.17      0.25        80\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.00      0.00      0.00       100\n",
      "           4       0.44      0.97      0.60       256\n",
      "           5       0.00      0.00      0.00       106\n",
      "\n",
      "    accuracy                           0.44       602\n",
      "   macro avg       0.17      0.23      0.17       602\n",
      "weighted avg       0.24      0.44      0.29       602\n",
      "\n",
      "[[ 14   0   1  65   0]\n",
      " [  1   0   0  59   0]\n",
      " [ 10   0   0  90   0]\n",
      " [  7   0   1 248   0]\n",
      " [  2   0   0 104   0]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:49:02.911465Z",
     "start_time": "2024-10-18T10:49:02.898384Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ba7df241a3e3db66",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
