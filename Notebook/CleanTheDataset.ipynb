{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Import all the necessary libraries & files",
   "id": "3231b5c7419f61d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:14:27.842481Z",
     "start_time": "2024-10-04T11:14:27.829436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(r'D:\\KDG\\2024-2025\\Semester 1\\DAI5\\GroupProject\\Functions')\n",
    "\n",
    "import Functions.functions as f\n",
    "\n",
    "os.chdir(r'D:\\KDG\\2024-2025\\Semester 1\\DAI5\\GroupProject\\Resources')"
   ],
   "id": "7a3c38819e46cdcf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2: Check if the number of max columns is the same as the number of min columns",
   "id": "7e19cd848787d5a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:14:30.835897Z",
     "start_time": "2024-09-28T14:14:30.810020Z"
    }
   },
   "cell_type": "code",
   "source": "print(f.nb_of_fields('employee_survey.csv', ','))",
   "id": "743db2fddfcaacac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 23]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 3: Read the CSV",
   "id": "5ae4b86d74d93d3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:17:03.198761Z",
     "start_time": "2024-10-04T11:17:03.154716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_values = ['n/a', 'na', 'nan', 'N/A', 'NA', 'NaN', 'NAN', '--', 'Missing']\n",
    "df = pd.read_csv('employee_survey.csv', na_values=missing_values, sep=',', decimal='.')\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # to see all the columns\n",
    "print(df.head())\n",
    "print(df.info())"
   ],
   "id": "3d02b9bb5a785ce7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmpID  Gender  Age MaritalStatus        JobLevel  Experience       Dept  \\\n",
      "0      6    Male   32       Married             Mid           7         IT   \n",
      "1     11  Female   34       Married             Mid          12    Finance   \n",
      "2     33  Female   23        Single  Intern/Fresher           1  Marketing   \n",
      "3     20  Female   29       Married          Junior           6         IT   \n",
      "4     28   Other   23        Single          Junior           1      Sales   \n",
      "\n",
      "     EmpType  WLB  WorkEnv  PhysicalActivityHours  Workload  Stress  \\\n",
      "0  Full-Time    1        1                    2.5         2       1   \n",
      "1  Full-Time    1        1                    1.8         2       2   \n",
      "2  Full-Time    2        4                    2.1         5       4   \n",
      "3   Contract    2        2                    1.9         3       1   \n",
      "4  Part-Time    3        1                    3.7         2       1   \n",
      "\n",
      "   SleepHours       CommuteMode  CommuteDistance  NumCompanies  TeamSize  \\\n",
      "0         7.6               Car               20             3        12   \n",
      "1         7.9               Car               15             4        11   \n",
      "2         6.5         Motorbike               17             0        30   \n",
      "3         7.5  Public Transport               13             2         9   \n",
      "4         4.9               Car               20             0         7   \n",
      "\n",
      "   NumReports  EduLevel  haveOT  TrainingHoursPerYear  JobSatisfaction  \n",
      "0           0  Bachelor    True                  33.5                5  \n",
      "1           0  Bachelor   False                  36.0                5  \n",
      "2           0  Bachelor    True                  10.5                5  \n",
      "3           0  Bachelor    True                  23.0                5  \n",
      "4           0  Bachelor   False                  20.5                5  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3025 entries, 0 to 3024\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   EmpID                  3025 non-null   int64  \n",
      " 1   Gender                 3025 non-null   object \n",
      " 2   Age                    3025 non-null   int64  \n",
      " 3   MaritalStatus          3025 non-null   object \n",
      " 4   JobLevel               3025 non-null   object \n",
      " 5   Experience             3025 non-null   int64  \n",
      " 6   Dept                   3025 non-null   object \n",
      " 7   EmpType                3025 non-null   object \n",
      " 8   WLB                    3025 non-null   int64  \n",
      " 9   WorkEnv                3025 non-null   int64  \n",
      " 10  PhysicalActivityHours  3025 non-null   float64\n",
      " 11  Workload               3025 non-null   int64  \n",
      " 12  Stress                 3025 non-null   int64  \n",
      " 13  SleepHours             3025 non-null   float64\n",
      " 14  CommuteMode            3025 non-null   object \n",
      " 15  CommuteDistance        3025 non-null   int64  \n",
      " 16  NumCompanies           3025 non-null   int64  \n",
      " 17  TeamSize               3025 non-null   int64  \n",
      " 18  NumReports             3025 non-null   int64  \n",
      " 19  EduLevel               3025 non-null   object \n",
      " 20  haveOT                 3025 non-null   bool   \n",
      " 21  TrainingHoursPerYear   3025 non-null   float64\n",
      " 22  JobSatisfaction        3025 non-null   int64  \n",
      "dtypes: bool(1), float64(3), int64(12), object(7)\n",
      "memory usage: 523.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4: Add some NaN ",
   "id": "a742345296993d9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:17:25.121518Z",
     "start_time": "2024-10-04T11:17:25.077229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seed for reproducibility\n",
    "\n",
    "np.random.seed(0)\n",
    " \n",
    "# Get the number of rows and columns in the DataFrame\n",
    "\n",
    "n_rows, n_cols = df.shape\n",
    " \n",
    "# Define how many random values you want to replace with NaN (1% of the dataset)\n",
    "\n",
    "nan_count = int(0.01 * n_rows * n_cols)\n",
    " \n",
    "# Randomly choose row indices and column indices to replace values with NaN\n",
    "\n",
    "row_indices = np.random.randint(0, n_rows, nan_count)\n",
    "\n",
    "col_indices = np.random.randint(0, n_cols, nan_count)\n",
    " \n",
    "# Replace the selected values with NaN\n",
    "\n",
    "df.values[row_indices, col_indices] = np.nan\n",
    " \n",
    "# Save the modified DataFrame to a new CSV file\n",
    "\n",
    "df.to_csv('modified_employees.csv', index=False)"
   ],
   "id": "8210d2b991f62898",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 5: Read the modified CSV file",
   "id": "95939b89bdae4354"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:17:55.230250Z",
     "start_time": "2024-10-04T11:17:53.853075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_values = ['n/a', 'na', 'nan', 'N/A', 'NA', 'NaN', 'NAN', '--', 'Missing']\n",
    "df = pd.read_csv('modified_employee_survey.csv', na_values=missing_values, sep=',', decimal='.')\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # to see all the columns\n",
    "print(df.head())\n",
    "print(df.info())"
   ],
   "id": "98b6639566391d42",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'modified_employee_survey.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m missing_values \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn/a\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mna\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnan\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mN/A\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNA\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNaN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNAN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodified_employee_survey.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecimal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m pd\u001B[38;5;241m.\u001B[39mset_option(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisplay.max_columns\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)  \u001B[38;5;66;03m# to see all the columns\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(df\u001B[38;5;241m.\u001B[39mhead())\n",
      "File \u001B[1;32mD:\\PythonEnv\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PythonEnv\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mD:\\PythonEnv\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PythonEnv\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mD:\\PythonEnv\\.venv\\lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'modified_employee_survey.csv'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4: Check the number of rows and columns",
   "id": "85200a68deddf03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:14:35.394405Z",
     "start_time": "2024-09-28T14:14:35.387619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_rows = df.shape[0]  # Get the number of rows\n",
    "print(num_rows)\n",
    "num_cols = df.shape[1]  # Get the number of columns\n",
    "print(num_cols)"
   ],
   "id": "b09c1bf848269f81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025\n",
      "23\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:14:37.241027Z",
     "start_time": "2024-09-28T14:14:37.185678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "total_cells = np.prod(df.shape)  # Use np.prod() instead of np.product()\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "percent_missing = (total_missing / total_cells) * 100\n",
    "\n",
    "print(percent_missing)\n"
   ],
   "id": "993ed1f0177056",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m missing_values_count \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39misnull()\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m----> 2\u001B[0m total_cells \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mprod(df\u001B[38;5;241m.\u001B[39mshape)  \u001B[38;5;66;03m# Use np.prod() instead of np.product()\u001B[39;00m\n\u001B[1;32m      3\u001B[0m total_missing \u001B[38;5;241m=\u001B[39m missing_values_count\u001B[38;5;241m.\u001B[39msum()\n\u001B[1;32m      5\u001B[0m percent_missing \u001B[38;5;241m=\u001B[39m (total_missing \u001B[38;5;241m/\u001B[39m total_cells) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:09:20.824809Z",
     "start_time": "2024-10-04T11:09:20.763651Z"
    }
   },
   "cell_type": "markdown",
   "source": "### Step 5: Drop the unnecessary columns",
   "id": "3b4ea2bc1b47e39f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:14:41.742254Z",
     "start_time": "2024-09-28T14:14:41.721166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.drop(['WLB', 'WorkEnv', 'NumCompanies', 'EduLevel'], axis=1)\n",
    "print(df.info())"
   ],
   "id": "4d853c84516947de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3025 entries, 0 to 3024\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   EmpID                  2996 non-null   float64\n",
      " 1   Gender                 2988 non-null   object \n",
      " 2   Age                    2989 non-null   float64\n",
      " 3   MaritalStatus          2994 non-null   object \n",
      " 4   JobLevel               2993 non-null   object \n",
      " 5   Experience             3005 non-null   float64\n",
      " 6   Dept                   2997 non-null   object \n",
      " 7   EmpType                2995 non-null   object \n",
      " 8   PhysicalActivityHours  2991 non-null   float64\n",
      " 9   Workload               3000 non-null   float64\n",
      " 10  Stress                 3001 non-null   float64\n",
      " 11  SleepHours             2990 non-null   float64\n",
      " 12  CommuteMode            2997 non-null   object \n",
      " 13  CommuteDistance        2990 non-null   float64\n",
      " 14  TeamSize               3000 non-null   float64\n",
      " 15  NumReports             3000 non-null   float64\n",
      " 16  haveOT                 2995 non-null   object \n",
      " 17  TrainingHoursPerYear   2997 non-null   float64\n",
      " 18  JobSatisfaction        2990 non-null   float64\n",
      "dtypes: float64(12), object(7)\n",
      "memory usage: 449.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 6: Check if NaN values are present",
   "id": "d728b4beb5b62bff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:14:44.218433Z",
     "start_time": "2024-09-28T14:14:44.170241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df.isna().sum().sum())  #total number of NA-values in de dataframe\n",
    "rowsWithNaN = df[df.isna().any(axis=1)]  #the rows containing NA's\n",
    "columnsWithNaN = df[df.columns[df.isna().any(axis=0)]]  #the colomns containing NA's\n",
    "print(columnsWithNaN)"
   ],
   "id": "e46069fd9e091904",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n",
      "       EmpID  Gender   Age MaritalStatus        JobLevel  Experience  \\\n",
      "0        6.0    Male  32.0       Married             Mid         7.0   \n",
      "1       11.0  Female  34.0       Married             Mid        12.0   \n",
      "2       33.0  Female  23.0        Single  Intern/Fresher         1.0   \n",
      "3       20.0  Female  29.0       Married          Junior         6.0   \n",
      "4       28.0   Other  23.0        Single          Junior         1.0   \n",
      "...      ...     ...   ...           ...             ...         ...   \n",
      "3020  2070.0    Male  47.0       Married            Lead        16.0   \n",
      "3021  2072.0  Female  47.0       Married            Lead         8.0   \n",
      "3022  2145.0    Male  41.0       Married            Lead        17.0   \n",
      "3023  2168.0  Female  54.0       Married            Lead        16.0   \n",
      "3024  2183.0  Female  44.0       Married            Lead        22.0   \n",
      "\n",
      "           Dept    EmpType  PhysicalActivityHours  Workload  Stress  \\\n",
      "0            IT  Full-Time                    2.5       2.0     1.0   \n",
      "1       Finance  Full-Time                    1.8       2.0     2.0   \n",
      "2     Marketing  Full-Time                    2.1       5.0     4.0   \n",
      "3            IT   Contract                    1.9       3.0     1.0   \n",
      "4         Sales  Part-Time                    3.7       2.0     1.0   \n",
      "...         ...        ...                    ...       ...     ...   \n",
      "3020  Marketing  Part-Time                    1.9       4.0     3.0   \n",
      "3021         IT   Contract                    1.5       2.0     1.0   \n",
      "3022         IT  Full-Time                    1.3       1.0     NaN   \n",
      "3023         IT  Full-Time                    2.5       3.0     3.0   \n",
      "3024  Marketing  Full-Time                    1.1       3.0     5.0   \n",
      "\n",
      "      SleepHours       CommuteMode  CommuteDistance  TeamSize  NumReports  \\\n",
      "0            7.6               Car             20.0      12.0         0.0   \n",
      "1            7.9               Car             15.0      11.0         0.0   \n",
      "2            6.5         Motorbike             17.0      30.0         0.0   \n",
      "3            7.5  Public Transport             13.0       9.0         0.0   \n",
      "4            4.9               Car             20.0       7.0         0.0   \n",
      "...          ...               ...              ...       ...         ...   \n",
      "3020         6.8  Public Transport              NaN      28.0         8.0   \n",
      "3021         6.9               Car             28.0      21.0         8.0   \n",
      "3022         6.1  Public Transport              9.0      23.0         3.0   \n",
      "3023         7.7  Public Transport             18.0      30.0         7.0   \n",
      "3024         6.2               Car             10.0      29.0         4.0   \n",
      "\n",
      "     haveOT  TrainingHoursPerYear  JobSatisfaction  \n",
      "0      True                  33.5              5.0  \n",
      "1     False                  36.0              5.0  \n",
      "2      True                  10.5              5.0  \n",
      "3      True                  23.0              5.0  \n",
      "4     False                  20.5              5.0  \n",
      "...     ...                   ...              ...  \n",
      "3020  False                  58.0              1.0  \n",
      "3021   True                  54.0              1.0  \n",
      "3022   True                  58.5              1.0  \n",
      "3023   True                  58.0              1.0  \n",
      "3024  False                  61.0              1.0  \n",
      "\n",
      "[3025 rows x 19 columns]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 7: Replace the NaN, still don't know how yet   ",
   "id": "223f0aca69fe7630"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:14:48.162975Z",
     "start_time": "2024-09-28T14:14:48.091525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Better sol\n",
    "# replace all NA's the value that comes directly after it in the same column, \n",
    "# then replace all the remaining na's with 0\n",
    "df_permits_with_na_imputed = df.fillna(method='bfill', axis=0).fillna(0)\n",
    "\n",
    "# Count the number of NaNs in the dataset to verify\n",
    "print(df_permits_with_na_imputed.isnull().sum().sum())\n",
    "\n",
    "df.head()\n"
   ],
   "id": "26e06b93052fc325",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/user/1000/app/com.jetbrains.IntelliJ-IDEA-Ultimate/ipykernel_2898/3269741163.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_permits_with_na_imputed = df.fillna(method='bfill', axis=0).fillna(0)\n",
      "/run/user/1000/app/com.jetbrains.IntelliJ-IDEA-Ultimate/ipykernel_2898/3269741163.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_permits_with_na_imputed = df.fillna(method='bfill', axis=0).fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   EmpID  Gender   Age MaritalStatus        JobLevel  Experience       Dept  \\\n",
       "0    6.0    Male  32.0       Married             Mid         7.0         IT   \n",
       "1   11.0  Female  34.0       Married             Mid        12.0    Finance   \n",
       "2   33.0  Female  23.0        Single  Intern/Fresher         1.0  Marketing   \n",
       "3   20.0  Female  29.0       Married          Junior         6.0         IT   \n",
       "4   28.0   Other  23.0        Single          Junior         1.0      Sales   \n",
       "\n",
       "     EmpType  PhysicalActivityHours  Workload  Stress  SleepHours  \\\n",
       "0  Full-Time                    2.5       2.0     1.0         7.6   \n",
       "1  Full-Time                    1.8       2.0     2.0         7.9   \n",
       "2  Full-Time                    2.1       5.0     4.0         6.5   \n",
       "3   Contract                    1.9       3.0     1.0         7.5   \n",
       "4  Part-Time                    3.7       2.0     1.0         4.9   \n",
       "\n",
       "        CommuteMode  CommuteDistance  TeamSize  NumReports haveOT  \\\n",
       "0               Car             20.0      12.0         0.0   True   \n",
       "1               Car             15.0      11.0         0.0  False   \n",
       "2         Motorbike             17.0      30.0         0.0   True   \n",
       "3  Public Transport             13.0       9.0         0.0   True   \n",
       "4               Car             20.0       7.0         0.0  False   \n",
       "\n",
       "   TrainingHoursPerYear  JobSatisfaction  \n",
       "0                  33.5              5.0  \n",
       "1                  36.0              5.0  \n",
       "2                  10.5              5.0  \n",
       "3                  23.0              5.0  \n",
       "4                  20.5              5.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmpID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Dept</th>\n",
       "      <th>EmpType</th>\n",
       "      <th>PhysicalActivityHours</th>\n",
       "      <th>Workload</th>\n",
       "      <th>Stress</th>\n",
       "      <th>SleepHours</th>\n",
       "      <th>CommuteMode</th>\n",
       "      <th>CommuteDistance</th>\n",
       "      <th>TeamSize</th>\n",
       "      <th>NumReports</th>\n",
       "      <th>haveOT</th>\n",
       "      <th>TrainingHoursPerYear</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Mid</td>\n",
       "      <td>7.0</td>\n",
       "      <td>IT</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Car</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>33.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Mid</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Car</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Intern/Fresher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Junior</td>\n",
       "      <td>6.0</td>\n",
       "      <td>IT</td>\n",
       "      <td>Contract</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Junior</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Part-Time</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Car</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>20.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### a) For EmpID, just drop those rows",
   "id": "b2ccfa99025aa14e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:14:53.943336Z",
     "start_time": "2024-09-28T14:14:53.933112Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.dropna(subset=['EmpID'])",
   "id": "621833ee3586ca3d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### b) For Age, take the mean",
   "id": "b74e8cda4cc1dfc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:14:55.913974Z",
     "start_time": "2024-09-28T14:14:55.906163Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:, 'Age'] = df['Age'].fillna(df['Age'].mean())",
   "id": "11e33191cb5294d8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### c) For Gender, fill with 'Other'",
   "id": "98a68805f64a3db4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:14:58.607329Z",
     "start_time": "2024-09-28T14:14:58.599386Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'Gender'] = df['Gender'].fillna('Other')",
   "id": "abcb950636d486dc",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### d) For Marital Status, use the mode",
   "id": "2eab32371548e46c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:00.670373Z",
     "start_time": "2024-09-28T14:15:00.660188Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'MaritalStatus'] = df['MaritalStatus'].fillna(df['MaritalStatus'].mode()[0])",
   "id": "d6615d8f5af49dec",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### e) For Job Level, use the Experience",
   "id": "b359323d353c7768"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:02.603223Z",
     "start_time": "2024-09-28T14:15:02.514096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fill_job_level(row):\n",
    "    if pd.isna(row['JobLevel']):\n",
    "        if row['Experience'] <= 2:\n",
    "            return 'Intern/Fresher'\n",
    "        elif row['Experience'] <= 5:\n",
    "            return 'Junior'\n",
    "        elif row['Experience'] <= 10:\n",
    "            return 'Mid'\n",
    "        else:\n",
    "            return 'Senior'\n",
    "    return row['JobLevel']\n",
    "\n",
    "df.loc[:,'JobLevel'] = df.apply(fill_job_level, axis=1)"
   ],
   "id": "a5fdd03828d8dbb8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### f) For Experience, use the Job Level",
   "id": "2a7f8191e8a8219b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:04.282883Z",
     "start_time": "2024-09-28T14:15:04.190640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fill_experience(row):\n",
    "    if pd.isna(row['Experience']):\n",
    "        if row['JobLevel'] == 'Intern/Fresher':\n",
    "            return 0\n",
    "        elif row['JobLevel'] == 'Junior':\n",
    "            return 2\n",
    "        elif row['JobLevel'] == 'Mid':\n",
    "            return 5\n",
    "        elif row['JobLevel'] == 'Senior':\n",
    "            return 10\n",
    "        elif row['JobLevel'] == 'Lead':\n",
    "            return 15\n",
    "    return row['Experience']\n",
    "\n",
    "df.loc[:,'Experience'] = df.apply(fill_experience, axis=1)\n"
   ],
   "id": "15f75f5eab28dfb3",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### g) For Dept, take the most frequent value(mode) ",
   "id": "2970d0c224eb2802"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:06.708686Z",
     "start_time": "2024-09-28T14:15:06.698708Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'Dept'] = df['Dept'].fillna(df['Dept'].mode()[0])",
   "id": "fee33476d1a5f9a7",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### f) For Emp Type, take the mode",
   "id": "86efc1d296a6b859"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:08.612859Z",
     "start_time": "2024-09-28T14:15:08.604759Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'EmpType'] = df['EmpType'].fillna(df['EmpType'].mode()[0])",
   "id": "7017c02751e8d842",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### g) For Physical Activity Hours, use the mean",
   "id": "614767455332ccb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:11.101787Z",
     "start_time": "2024-09-28T14:15:11.093061Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'PhysicalActivityHours'] = df['PhysicalActivityHours'].fillna(df['PhysicalActivityHours'].mean())",
   "id": "59b9db0f253ea4cd",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### h) For Workload, use the median",
   "id": "fd489c73889ae94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:13.187844Z",
     "start_time": "2024-09-28T14:15:13.179662Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'Workload'] = df['Workload'].fillna(df['Workload'].median())",
   "id": "f00235a613431e72",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### i) For Stress, use the median",
   "id": "25e6bac8f6e62cd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T13:16:32.256560Z",
     "start_time": "2024-09-28T13:16:32.249689Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'Stress'] = df['Stress'].fillna(df['Stress'].median())",
   "id": "f98daa331652c529",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### j) For Sleep Hours, use the mean",
   "id": "60c3fb0e37ed6007"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:14.981771Z",
     "start_time": "2024-09-28T14:15:14.973634Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'SleepHours'] = df['SleepHours'].fillna(df['SleepHours'].mean())",
   "id": "d948a1dcc27c7641",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### k) For Commute Mode, use the most frequent mode of commuting",
   "id": "d7f21aedff0909e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:16.589827Z",
     "start_time": "2024-09-28T14:15:16.576447Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'CommuteMode'] = df['CommuteMode'].fillna(df['CommuteMode'].mode()[0])",
   "id": "528e6409046bed2b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### l) For Commute Distance, use the mean",
   "id": "7043251b29e38aee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:19.501653Z",
     "start_time": "2024-09-28T14:15:19.491274Z"
    }
   },
   "cell_type": "code",
   "source": "df['CommuteDistance'] = df['CommuteDistance'].fillna(df['CommuteDistance'].mean())",
   "id": "820e12f903265ff3",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### m) For Team Size, use the mean",
   "id": "a80f870943653584"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:21.262019Z",
     "start_time": "2024-09-28T14:15:21.253913Z"
    }
   },
   "cell_type": "code",
   "source": "df['TeamSize'] = df['TeamSize'].fillna(df['TeamSize'].mean())",
   "id": "145d73274df47d63",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### n) For Num Reports, use the Job Level",
   "id": "3f3a250cd673adcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:23.226929Z",
     "start_time": "2024-09-28T14:15:23.135878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fill_num_reports(row):\n",
    "    if pd.isna(row['NumReports']):\n",
    "        if row['JobLevel'] in ['Senior', 'Lead']:\n",
    "            return df['NumReports'].mean()  # Use the mean if Senior or Lead\n",
    "        else:\n",
    "            return 0  # Otherwise set to 0\n",
    "    return row['NumReports']\n",
    "\n",
    "df['NumReports'] = df.apply(fill_num_reports, axis=1)"
   ],
   "id": "67d5aab16ca3bfdf",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### o) For have OT (overtime), use the most frequent value",
   "id": "99474aea40668aab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:27.565586Z",
     "start_time": "2024-09-28T14:15:27.556309Z"
    }
   },
   "cell_type": "code",
   "source": "df.loc[:,'haveOT'] = df['haveOT'].fillna(df['haveOT'].mode()[0])",
   "id": "859d991dd6c2ac2d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/user/1000/app/com.jetbrains.IntelliJ-IDEA-Ultimate/ipykernel_2898/2462339074.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.loc[:,'haveOT'] = df['haveOT'].fillna(df['haveOT'].mode()[0])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### p) For Training Hours Per Year, use the mean",
   "id": "9fff6c523f403b55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:30.065776Z",
     "start_time": "2024-09-28T14:15:30.058928Z"
    }
   },
   "cell_type": "code",
   "source": "df['TrainingHoursPerYear'] = df['TrainingHoursPerYear'].fillna(df['TrainingHoursPerYear'].mean())",
   "id": "5fdc5e8ed9e3622f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### q) JobSatisfaction, use the median",
   "id": "db2db387d734cfab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:32.106133Z",
     "start_time": "2024-09-28T14:15:32.096282Z"
    }
   },
   "cell_type": "code",
   "source": "df['JobSatisfaction'] = df['JobSatisfaction'].fillna(df['JobSatisfaction'].median())",
   "id": "4d82810817a8fd2f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 8: Remove the outliers",
   "id": "706c768d93a22363"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:35.039658Z",
     "start_time": "2024-09-28T14:15:34.988558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outliers = f.get_outliers(df['Age'])\n",
    "df = df[~df['Age'].isin(outliers)]\n",
    "\n",
    "outliers = f.get_outliers(df['Experience'])\n",
    "df = df[~df['Experience'].isin(outliers)]\n",
    "\n",
    "outliers = f.get_outliers(df['PhysicalActivityHours'])\n",
    "df = df[~df['PhysicalActivityHours'].isin(outliers)]\n",
    "\n",
    "outliers = f.get_outliers(df['SleepHours'])\n",
    "df = df[~df['SleepHours'].isin(outliers)]\n",
    "\n",
    "outliers = f.get_outliers(df['CommuteDistance'])\n",
    "df = df[~df['CommuteDistance'].isin(outliers)]\n",
    "\n",
    "outliers = f.get_outliers(df['TeamSize'])\n",
    "df = df[~df['TeamSize'].isin(outliers)]\n",
    "\n",
    "outliers = f.get_outliers(df['NumReports'])\n",
    "df = df[~df['NumReports'].isin(outliers)]\n",
    "\n",
    "outliers = f.get_outliers(df['TrainingHoursPerYear'])\n",
    "df = df[~df['TrainingHoursPerYear'].isin(outliers)]"
   ],
   "id": "e91a908c49932a58",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 9: Make each nominal variable a disordered categorical variable and each ordinal variable, an ordered categorical variable",
   "id": "9681ebab7d398a0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:39.120935Z",
     "start_time": "2024-09-28T14:15:39.064858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['Gender'] = df['Gender'].astype(pd.CategoricalDtype(categories=df['Gender'].unique()))\n",
    "df['MaritalStatus'] = df['MaritalStatus'].astype(pd.CategoricalDtype(categories=df['MaritalStatus'].unique()))\n",
    "df['Dept'] = df['Dept'].astype(pd.CategoricalDtype(categories=df['Dept'].unique()))\n",
    "df['EmpType'] = df['EmpType'].astype(pd.CategoricalDtype(categories=df['EmpType'].unique()))\n",
    "df['CommuteMode'] = df['CommuteMode'].astype(pd.CategoricalDtype(categories=df['CommuteMode'].unique()))\n",
    "df['haveOT'] = df['haveOT'].astype(pd.CategoricalDtype(categories=df['haveOT'].unique()))\n",
    "\n",
    "print(df['JobLevel'].unique())\n",
    "df['JobLevel'] = df['JobLevel'].astype(\n",
    "    pd.CategoricalDtype(categories=['Intern/Fresher', 'Junior', 'Mid', 'Senior', 'Lead'], ordered=True))\n",
    "\n",
    "df['Workload'] = df['Workload'].astype(\n",
    "    pd.CategoricalDtype(categories=[1,2,3,4,5], ordered=True))\n",
    "\n",
    "df['Stress'] = df['Stress'].astype(\n",
    "    pd.CategoricalDtype(categories=[1,2,3,4,5], ordered=True))\n",
    "\n",
    "df['JobSatisfaction'] = df['JobSatisfaction'].astype(\n",
    "    pd.CategoricalDtype(categories=[1,2,3,4,5], ordered=True))\n",
    "\n",
    "print(df.info())\n"
   ],
   "id": "876e1afb2342ce18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mid' 'Intern/Fresher' 'Junior' 'Senior' 'Lead']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2976 entries, 0 to 3024\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   EmpID                  2976 non-null   float64 \n",
      " 1   Gender                 2976 non-null   category\n",
      " 2   Age                    2976 non-null   float64 \n",
      " 3   MaritalStatus          2976 non-null   category\n",
      " 4   JobLevel               2976 non-null   category\n",
      " 5   Experience             2976 non-null   float64 \n",
      " 6   Dept                   2976 non-null   category\n",
      " 7   EmpType                2976 non-null   category\n",
      " 8   PhysicalActivityHours  2976 non-null   float64 \n",
      " 9   Workload               2976 non-null   category\n",
      " 10  Stress                 2953 non-null   category\n",
      " 11  SleepHours             2976 non-null   float64 \n",
      " 12  CommuteMode            2976 non-null   category\n",
      " 13  CommuteDistance        2976 non-null   float64 \n",
      " 14  TeamSize               2976 non-null   float64 \n",
      " 15  NumReports             2976 non-null   float64 \n",
      " 16  haveOT                 2976 non-null   category\n",
      " 17  TrainingHoursPerYear   2976 non-null   float64 \n",
      " 18  JobSatisfaction        2976 non-null   category\n",
      "dtypes: category(10), float64(9)\n",
      "memory usage: 263.5 KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 10: Normalize the data",
   "id": "97f911db2d30dd8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:44.172127Z",
     "start_time": "2024-09-28T14:15:44.141577Z"
    }
   },
   "cell_type": "code",
   "source": "df = f.normalize_values(pd.DataFrame(df), f.Zscore_norm)\n",
   "id": "b70344e871985f01",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T13:32:12.746055Z",
     "start_time": "2024-09-28T13:32:12.580456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # william version\n",
    "# # Filter for positive job satisfaction (shift values to be positive)\n",
    "# # Adding a small constant (e.g., 1) to shift the range from [0, 5] to [1, 6]\n",
    "# \n",
    "# import numpy as np\n",
    "# \n",
    "# # for Box-Cox Transformation\n",
    "# from scipy import stats\n",
    "# \n",
    "# \n",
    "# # plotting modules\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# import os\n",
    "# \n",
    "# os.chdir(r'/home/zamlamb/KdG/Data n AI 5/Notebooks/dataset')\n",
    "# \n",
    "# cleaned_data = pd.read_csv(\"cleaned_employee.csv\")\n",
    "# \n",
    "# adjusted_job_satisfaction = cleaned_data['JobSatisfaction'] + 1\n",
    "# \n",
    "# # Normalize the job satisfaction data with Box-Cox\n",
    "# normalized_data = pd.Series(stats.boxcox(adjusted_job_satisfaction)[0], name='JobSatisfaction', index=cleaned_data.index)\n",
    "# \n",
    "# # Print original and normalized data statistics\n",
    "# print('Original data\\nPreview:\\n', adjusted_job_satisfaction.head())\n",
    "# print('Minimum value\\n', float(adjusted_job_satisfaction.min()),\n",
    "#       '\\nMaximum value\\n', float(adjusted_job_satisfaction.max()))\n",
    "# print('_'*30)\n",
    "# \n",
    "# print('Normalized data\\nPreview:\\n', normalized_data.head())\n",
    "# print('Minimum value\\n', float(normalized_data.min()),\n",
    "#       '\\nMaximum value\\n', float(normalized_data.max()))\n",
    "# \n",
    "# # Plotting the original and normalized data\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "# \n",
    "# # Original Data Plot\n",
    "# sns.histplot(adjusted_job_satisfaction, ax=ax[0], kde=True, color='blue', bins=6)\n",
    "# ax[0].set_title(\"Original Job Satisfaction Data (Adjusted)\")\n",
    "# ax[0].set_xlabel(\"Job Satisfaction (Adjusted)\")\n",
    "# ax[0].set_ylabel(\"Frequency\")\n",
    "# \n",
    "# # Normalized Data Plot\n",
    "# sns.histplot(normalized_data, ax=ax[1], kde=True, color='red', bins=10)\n",
    "# ax[1].set_title(\"Normalized Job Satisfaction Data\")\n",
    "# ax[1].set_xlabel(\"Job Satisfaction (Normalized)\")\n",
    "# ax[1].set_ylabel(\"Frequency\")\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# \n",
    "# \n"
   ],
   "id": "1e3c2c8b9c9a8632",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cleaned_employee.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 19\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m     17\u001B[0m os\u001B[38;5;241m.\u001B[39mchdir(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/home/zamlamb/KdG/Data n AI 5/Notebooks/dataset\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 19\u001B[0m cleaned_data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcleaned_employee.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m adjusted_job_satisfaction \u001B[38;5;241m=\u001B[39m cleaned_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJobSatisfaction\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Normalize the job satisfaction data with Box-Cox\u001B[39;00m\n",
      "File \u001B[0;32m~/KdG/Data n AI 5/Notebooks/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/KdG/Data n AI 5/Notebooks/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/KdG/Data n AI 5/Notebooks/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/KdG/Data n AI 5/Notebooks/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/KdG/Data n AI 5/Notebooks/venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'cleaned_employee.csv'"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step 10.5: Scaling\n",
   "id": "a3e5c2721b56eedf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # # william version\n",
    "# for min_max scaling\n",
    "# from mlxtend.preprocessing import minmax_scaling\n",
    "# # Filter for positive job satisfaction (shift values to be positive)\n",
    "# # Adding a small constant (e.g., 1) to shift the range from [0, 5] to [1, 6]\n",
    "# adjusted_job_satisfaction = cleaned_data['JobSatisfaction'] + 1\n",
    "# \n",
    "# # Normalize the job satisfaction data with Box-Cox\n",
    "# normalized_data = pd.Series(stats.boxcox(adjusted_job_satisfaction)[0], name='JobSatisfaction', index=cleaned_data.index)\n",
    "# \n",
    "# # Print original and normalized data statistics\n",
    "# print('Original data\\nPreview:\\n', adjusted_job_satisfaction.head())\n",
    "# print('Minimum value\\n', float(adjusted_job_satisfaction.min()),\n",
    "#       '\\nMaximum value\\n', float(adjusted_job_satisfaction.max()))\n",
    "# print('_'*30)\n",
    "# \n",
    "# print('Normalized data\\nPreview:\\n', normalized_data.head())\n",
    "# print('Minimum value\\n', float(normalized_data.min()),\n",
    "#       '\\nMaximum value\\n', float(normalized_data.max()))\n",
    "# \n",
    "# # Plotting the original and normalized data\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "# \n",
    "# # Original Data Plot\n",
    "# sns.histplot(adjusted_job_satisfaction, ax=ax[0], kde=True, color='blue', bins=6)\n",
    "# ax[0].set_title(\"Original Job Satisfaction Data (Adjusted)\")\n",
    "# ax[0].set_xlabel(\"Job Satisfaction (Adjusted)\")\n",
    "# ax[0].set_ylabel(\"Frequency\")\n",
    "# \n",
    "# # Normalized Data Plot\n",
    "# sns.histplot(normalized_data, ax=ax[1], kde=True, color='red', bins=10)\n",
    "# ax[1].set_title(\"Normalized Job Satisfaction Data\")\n",
    "# ax[1].set_xlabel(\"Job Satisfaction (Normalized)\")\n",
    "# ax[1].set_ylabel(\"Frequency\")\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# \n",
    "# \n"
   ],
   "id": "667fbd1e44942e7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 11: Check the df",
   "id": "4c17597010dcd510"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:15:49.303539Z",
     "start_time": "2024-09-28T14:15:49.262921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ],
   "id": "ecedb602fee72054",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      EmpID  Gender       Age MaritalStatus        JobLevel  Experience  \\\n",
      "0 -1.725515    Male -0.364117       Married             Mid   -0.291683   \n",
      "1 -1.719795  Female -0.166847       Married             Mid    0.416466   \n",
      "2 -1.694629  Female -1.251834        Single  Intern/Fresher   -1.141462   \n",
      "3 -1.709500  Female -0.660023       Married          Junior   -0.433313   \n",
      "4 -1.700348   Other -1.251834        Single          Junior   -1.141462   \n",
      "\n",
      "        Dept    EmpType  PhysicalActivityHours Workload Stress  SleepHours  \\\n",
      "0         IT  Full-Time               0.505244        2      1    0.603594   \n",
      "1    Finance  Full-Time              -0.230791        2      2    0.910380   \n",
      "2  Marketing  Full-Time               0.084653        5      4   -0.521287   \n",
      "3         IT   Contract              -0.125643        3      1    0.501332   \n",
      "4      Sales  Part-Time               1.767020        2      1   -2.157477   \n",
      "\n",
      "        CommuteMode  CommuteDistance  TeamSize  NumReports haveOT  \\\n",
      "0               Car         0.777895 -0.682421   -0.777629   True   \n",
      "1               Car         0.179010 -0.833690   -0.777629  False   \n",
      "2         Motorbike         0.418564  2.040415   -0.777629   True   \n",
      "3  Public Transport        -0.060544 -1.136227   -0.777629   True   \n",
      "4               Car         0.777895 -1.438765   -0.777629  False   \n",
      "\n",
      "   TrainingHoursPerYear JobSatisfaction  \n",
      "0             -0.276046               5  \n",
      "1             -0.091076               5  \n",
      "2             -1.977769               5  \n",
      "3             -1.052919               5  \n",
      "4             -1.237889               5  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2976 entries, 0 to 3024\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   EmpID                  2976 non-null   float64 \n",
      " 1   Gender                 2976 non-null   category\n",
      " 2   Age                    2976 non-null   float64 \n",
      " 3   MaritalStatus          2976 non-null   category\n",
      " 4   JobLevel               2976 non-null   category\n",
      " 5   Experience             2976 non-null   float64 \n",
      " 6   Dept                   2976 non-null   category\n",
      " 7   EmpType                2976 non-null   category\n",
      " 8   PhysicalActivityHours  2976 non-null   float64 \n",
      " 9   Workload               2976 non-null   category\n",
      " 10  Stress                 2953 non-null   category\n",
      " 11  SleepHours             2976 non-null   float64 \n",
      " 12  CommuteMode            2976 non-null   category\n",
      " 13  CommuteDistance        2976 non-null   float64 \n",
      " 14  TeamSize               2976 non-null   float64 \n",
      " 15  NumReports             2976 non-null   float64 \n",
      " 16  haveOT                 2976 non-null   category\n",
      " 17  TrainingHoursPerYear   2976 non-null   float64 \n",
      " 18  JobSatisfaction        2976 non-null   category\n",
      "dtypes: category(10), float64(9)\n",
      "memory usage: 263.5 KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:16:10.385131Z",
     "start_time": "2024-09-28T14:16:10.251059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save the cleaned data to a new CSV file\n",
    "# Save the cleaned DataFrame to a CSV file in the current directory\n",
    "output_file = 'cleaned_employees.csv'\n",
    "df_permits_with_na_imputed.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned DataFrame saved to {output_file}\")\n",
    "\n",
    "df_permits_with_na_imputed.head()\n"
   ],
   "id": "d36b11b7a7c89183",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame saved to cleaned_employees.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   EmpID  Gender   Age MaritalStatus        JobLevel  Experience       Dept  \\\n",
       "0    6.0    Male  32.0       Married             Mid         7.0         IT   \n",
       "1   11.0  Female  34.0       Married             Mid        12.0    Finance   \n",
       "2   33.0  Female  23.0        Single  Intern/Fresher         1.0  Marketing   \n",
       "3   20.0  Female  29.0       Married          Junior         6.0         IT   \n",
       "4   28.0   Other  23.0        Single          Junior         1.0      Sales   \n",
       "\n",
       "     EmpType  PhysicalActivityHours  Workload  Stress  SleepHours  \\\n",
       "0  Full-Time                    2.5       2.0     1.0         7.6   \n",
       "1  Full-Time                    1.8       2.0     2.0         7.9   \n",
       "2  Full-Time                    2.1       5.0     4.0         6.5   \n",
       "3   Contract                    1.9       3.0     1.0         7.5   \n",
       "4  Part-Time                    3.7       2.0     1.0         4.9   \n",
       "\n",
       "        CommuteMode  CommuteDistance  TeamSize  NumReports  haveOT  \\\n",
       "0               Car             20.0      12.0         0.0    True   \n",
       "1               Car             15.0      11.0         0.0   False   \n",
       "2         Motorbike             17.0      30.0         0.0    True   \n",
       "3  Public Transport             13.0       9.0         0.0    True   \n",
       "4               Car             20.0       7.0         0.0   False   \n",
       "\n",
       "   TrainingHoursPerYear  JobSatisfaction  \n",
       "0                  33.5              5.0  \n",
       "1                  36.0              5.0  \n",
       "2                  10.5              5.0  \n",
       "3                  23.0              5.0  \n",
       "4                  20.5              5.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmpID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Dept</th>\n",
       "      <th>EmpType</th>\n",
       "      <th>PhysicalActivityHours</th>\n",
       "      <th>Workload</th>\n",
       "      <th>Stress</th>\n",
       "      <th>SleepHours</th>\n",
       "      <th>CommuteMode</th>\n",
       "      <th>CommuteDistance</th>\n",
       "      <th>TeamSize</th>\n",
       "      <th>NumReports</th>\n",
       "      <th>haveOT</th>\n",
       "      <th>TrainingHoursPerYear</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Mid</td>\n",
       "      <td>7.0</td>\n",
       "      <td>IT</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Car</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>33.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Mid</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Car</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Intern/Fresher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Junior</td>\n",
       "      <td>6.0</td>\n",
       "      <td>IT</td>\n",
       "      <td>Contract</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Junior</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Part-Time</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Car</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>20.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
