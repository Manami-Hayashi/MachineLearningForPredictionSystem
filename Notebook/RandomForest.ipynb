{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. import necessary libraries",
   "id": "931c0c5e0afdc54d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-18T09:31:27.889159Z",
     "start_time": "2024-10-18T09:31:27.867555Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import randint\n",
    "import joblib\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Load data",
   "id": "5ad93a9b822f77e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:14:24.314311Z",
     "start_time": "2024-10-18T09:14:24.289156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load data\n",
    "df = pd.read_csv('../Resources/modified_employees.csv')\n"
   ],
   "id": "4999df0d5bcdee3e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:14:25.917964Z",
     "start_time": "2024-10-18T09:14:25.910026Z"
    }
   },
   "cell_type": "code",
   "source": "df.dtypes",
   "id": "f5fd351ed8ec45e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobSatisfaction      object\n",
       "Workload_Binned       int64\n",
       "SleepHours_Binned     int64\n",
       "Age_Binned           object\n",
       "Stress_Binned         int64\n",
       "Experience_Binned    object\n",
       "JobLevel             object\n",
       "Gender               object\n",
       "MaritalStatus        object\n",
       "Dept                 object\n",
       "EmpType              object\n",
       "haveOT_Binned        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Initialize random forest model for Regression",
   "id": "cc5b40638ac3d535"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:14:46.841163Z",
     "start_time": "2024-10-18T09:14:46.790105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define all features and target\n",
    "features = [\"Workload_Binned\", \"Stress_Binned\", \"SleepHours_Binned\"]\n",
    "\n",
    "target = \"JobSatisfaction\"\n",
    "\n",
    "# Extract X and y\n",
    "x = df[features]  # Features\n",
    "y = df[target]    # Target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_regressor.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n"
   ],
   "id": "f323329dc0979746",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Dissatisfied'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m rf_regressor \u001B[38;5;241m=\u001B[39m RandomForestRegressor(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m \u001B[43mrf_regressor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Make predictions on the test set\u001B[39;00m\n\u001B[0;32m     20\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m rf_regressor\u001B[38;5;241m.\u001B[39mpredict(x_test)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    385\u001B[0m y, expanded_class_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_y_class_weight(y)\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(y, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m!=\u001B[39m DOUBLE \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m y\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mcontiguous:\n\u001B[1;32m--> 388\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mascontiguousarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDOUBLE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m expanded_class_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'Dissatisfied'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## first output\n",
    "### MSE = 1.786 indicates this model has poor peformance.\n",
    "### R-squared values = -0.122 means this model performs worse than a simple horizontal line."
   ],
   "id": "e1a2df8430bb3f5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:24:32.112529Z",
     "start_time": "2024-10-11T12:24:32.096521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"features shape: {x.shape}\")\n",
    "print(f\"target shape: {y.shape}\")"
   ],
   "id": "3ad1a99b3bb354ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (3007, 3)\n",
      "target shape: (3007,)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Hyperparameter tuning using RandomSearch\n",
   "id": "3cfbcce3ceb52516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:44:21.479467Z",
     "start_time": "2024-10-18T06:44:19.524413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameter space \n",
    "hyperparameters = {\n",
    "    'n_estimators': randint(100, 500),               # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],                 # Maximum depth of each tree\n",
    "    'min_samples_split': randint(2, 11),             # Minimum samples required to split a node\n",
    "    'min_samples_leaf': randint(1, 5),               # Minimum samples required at a leaf node\n",
    "    'max_features': ['auto']                # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "# Set up the RandomizedSearchCV with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=hyperparameters, n_iter=50, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the training data\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(x_test)\n",
    "\n",
    "# Evaluate the model with best hyperparameters\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output the evaluation results\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n"
   ],
   "id": "20ef42fa0566300a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 250 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n50 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 388, in fit\n    y = np.ascontiguousarray(y, dtype=DOUBLE)\nValueError: could not convert string to float: 'Neutral'\n\n--------------------------------------------------------------------------------\n200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 388, in fit\n    y = np.ascontiguousarray(y, dtype=DOUBLE)\nValueError: could not convert string to float: 'Dissatisfied'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m random_search \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(estimator\u001B[38;5;241m=\u001B[39mrf, param_distributions\u001B[38;5;241m=\u001B[39mhyperparameters, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Fit the RandomizedSearchCV to the training data\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m \u001B[43mrandom_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Get the best hyperparameters\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Hyperparameters: \u001B[39m\u001B[38;5;124m\"\u001B[39m, random_search\u001B[38;5;241m.\u001B[39mbest_params_)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    868\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    869\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    870\u001B[0m     )\n\u001B[0;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 874\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    878\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1767\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1768\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1769\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1770\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m   1771\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1772\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    844\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    845\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    846\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    847\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    848\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    849\u001B[0m     )\n\u001B[1;32m--> 851\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m    855\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m    856\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m    857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    361\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    362\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    363\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    364\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    365\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    366\u001B[0m     )\n\u001B[1;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    370\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    371\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    372\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    376\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    377\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 250 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n50 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 388, in fit\n    y = np.ascontiguousarray(y, dtype=DOUBLE)\nValueError: could not convert string to float: 'Neutral'\n\n--------------------------------------------------------------------------------\n200 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 388, in fit\n    y = np.ascontiguousarray(y, dtype=DOUBLE)\nValueError: could not convert string to float: 'Dissatisfied'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Second output\n",
    "### Best Hyperparameters:  {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "\n",
    "### MSE =1.538 \n",
    "### -> that it minimuze the error but still not good enough.\n",
    "\n",
    "### R-squared: 0.033 \n",
    "### -> means only 3.3% of hte variance in JobSatisfaction is explained by our features. \n",
    "\n",
    "## Conclusion\n",
    "### possible causes:  less features to predict JobSatisfaction, or the model is not suitable for this dataset."
   ],
   "id": "c66ce346bdbe05e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest For Classification",
   "id": "b322c3b3db7a0e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Preparation",
   "id": "52a9e52d666e570a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load data\n",
    "df = pd.read_csv('../Resources/processed_features_job_satisfaction.csv')\n",
    "df.dtypes"
   ],
   "id": "e60ff6be6edb00c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 1. Defining Features and Target Variable"
   ],
   "id": "aed1589fe9018ca0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:15:02.420025Z",
     "start_time": "2024-10-18T09:15:02.405467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define all features and target\n",
    "features = [\"Workload_Binned\", \"Stress_Binned\", \"SleepHours_Binned\"]\n",
    "\n",
    "target = \"JobSatisfaction\"  # Make sure that 'JobSatisfaction' is a categorical variable for classification\n",
    "\n",
    "# Extract X and y\n",
    "x = df[features]  # Features\n",
    "y = df[target]    # Target\n",
    "\n"
   ],
   "id": "71559586e7859138",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Splitting Data into Training and Testing set\n",
    "### train_test_split randomly splits the dataset into two parts: \n",
    "### * 80% for training\n",
    "### * 20% for testing\n",
    "### * random_state=42 ensures the split is reproducible"
   ],
   "id": "93054b41d8af02e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:15:05.942172Z",
     "start_time": "2024-10-18T09:15:05.928171Z"
    }
   },
   "cell_type": "code",
   "source": "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)",
   "id": "e61d17a7d5a3d2a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Initializing and Training the Rando Forest Classifier\n",
    "### This block initializes the RandomForestClassifier and trains it using the training data (x_train, y_train)."
   ],
   "id": "bdf9252e50f4430e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:15:08.436698Z",
     "start_time": "2024-10-18T09:15:08.243942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, min_samples_split=2, min_samples_leaf=1, max_features='auto')\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(x_train, y_train)"
   ],
   "id": "33504d1691bdb7b5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='auto', random_state=42)"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=&#x27;auto&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=&#x27;auto&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Making Predictions and Evaluating the Classifier\n",
    "### After the classifier is trained, predictions are made on the test data (x_test), and the performance is evaluated using metrics like accuracy, classification report, and confusion matrix."
   ],
   "id": "60ca0c91f443802e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:15:15.501162Z",
     "start_time": "2024-10-18T09:15:15.463553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ],
   "id": "b579bd526b61841c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4318936877076412\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Dissatisfied       0.00      0.00      0.00        60\n",
      "          Neutral       0.24      0.19      0.21       100\n",
      "        Satisfied       0.47      0.86      0.61       256\n",
      "   Very Satisfied       0.37      0.07      0.11       106\n",
      "Very dissatisfied       0.38      0.19      0.25        80\n",
      "\n",
      "         accuracy                           0.43       602\n",
      "        macro avg       0.29      0.26      0.24       602\n",
      "     weighted avg       0.36      0.43      0.35       602\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   7  50   2   1]\n",
      " [  0  19  71   0  10]\n",
      " [  0  21 219   7   9]\n",
      " [  0  10  85   7   4]\n",
      " [  1  21  40   3  15]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Hyperparameter Tuning using RandomizedSearchCV\n",
    "### This block performs hyperparameter tuning using RandomizedSearchCV. It randomly searches over a range of hyperparameters to find the best configuration.\n",
    "\n",
    "### The hyperparameter space is defined for n_estimators, max_depth, min_samples_split, min_samples_leaf, and max_features. RandomizedSearchCV performs 5-fold cross-validation and iterates through 50 different combinations of parameters."
   ],
   "id": "a9b69f2ab9115ca8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:19:22.087785Z",
     "start_time": "2024-10-18T09:18:42.024698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the RandomForestClassifier for hyperparameter tuning\n",
    "rf = RandomForestClassifier( n_estimators=500, max_leaf_nodes=16, max_features='sqrt', random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Define the hyperparameter space\n",
    "hyperparameters = {\n",
    "    'n_estimators': randint(100, 500),               # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],                 # Maximum depth of each tree\n",
    "    'min_samples_split': randint(2, 11),             # Minimum samples required to split a node\n",
    "    'min_samples_leaf': randint(1, 5),               # Minimum samples required at a leaf node\n",
    "    'max_features': ['auto', 'sqrt'],                # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "# Set up the RandomizedSearchCV with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=hyperparameters, n_iter=50, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the RandomizedSearchCV to the training data\n",
    "random_search.fit(x_train, y_train)\n"
   ],
   "id": "b39cf9878c746cda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(max_features='auto',\n",
       "                                                    max_leaf_nodes=16,\n",
       "                                                    n_estimators=500, n_jobs=-1,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 20, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001AF7DEDF310>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001AF7DF7ABB0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001AF7E284AF0>},\n",
       "                   random_state=42, verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(max_features=&#x27;auto&#x27;,\n",
       "                                                    max_leaf_nodes=16,\n",
       "                                                    n_estimators=500, n_jobs=-1,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001AF7DEDF310&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001AF7DF7ABB0&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001AF7E284AF0&gt;},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(max_features=&#x27;auto&#x27;,\n",
       "                                                    max_leaf_nodes=16,\n",
       "                                                    n_estimators=500, n_jobs=-1,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001AF7DEDF310&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001AF7DF7ABB0&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001AF7E284AF0&gt;},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=&#x27;auto&#x27;, max_leaf_nodes=16, n_estimators=500,\n",
       "                       n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=&#x27;auto&#x27;, max_leaf_nodes=16, n_estimators=500,\n",
       "                       n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Evaluating the Best Model after Hyperparameter Tuning",
   "id": "8ae719445552928b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:31:35.768065Z",
     "start_time": "2024-10-18T09:31:35.616459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(x_test)\n",
    "\n",
    "# Save the best model to a file\n",
    "joblib.dump(best_rf, \"random_forest_model.pkl\")\n",
    "\n",
    "# Evaluate the model with best hyperparameters\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ],
   "id": "6bd0515247d06e16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 297}\n",
      "Accuracy: 0.4435215946843854\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Dissatisfied       0.00      0.00      0.00        60\n",
      "          Neutral       0.21      0.04      0.07       100\n",
      "        Satisfied       0.45      0.95      0.61       256\n",
      "   Very Satisfied       0.62      0.05      0.09       106\n",
      "Very dissatisfied       0.40      0.20      0.27        80\n",
      "\n",
      "         accuracy                           0.44       602\n",
      "        macro avg       0.34      0.25      0.21       602\n",
      "     weighted avg       0.39      0.44      0.32       602\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   1  58   0   1]\n",
      " [  0   4  84   0  12]\n",
      " [  0   3 242   3   8]\n",
      " [  0   2  96   5   3]\n",
      " [  0   9  55   0  16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Save the results to a CSV file",
   "id": "91da8ce1c3d46902"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T08:42:22.280288Z",
     "start_time": "2024-10-18T08:42:22.236524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# Get the classification report as a dictionary\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Convert the classification report dictionary into a DataFrame\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Get the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Convert the confusion matrix to a DataFrame\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, \n",
    "                              index=[f\"Actual_{i}\" for i in range(1, len(conf_matrix) + 1)],\n",
    "                              columns=[f\"Predicted_{i}\" for i in range(1, len(conf_matrix) + 1)])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame for accuracy\n",
    "accuracy_df = pd.DataFrame({\"Metric\": [\"Accuracy\"], \"Value\": [accuracy]})\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "final_df = pd.concat([report_df, conf_matrix_df, accuracy_df], axis=0, ignore_index=False)\n",
    "\n",
    "# Save the final DataFrame to a CSV file in the \"Resource\" folder\n",
    "final_df.to_csv(\"classification_results.csv\", index=True)\n",
    "\n",
    "print(\"All results saved to a single CSV file in the 'Resource' folder.\")\n"
   ],
   "id": "318645e934093dc2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mnmhy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All results saved to a single CSV file in the 'Resource' folder.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Memo\n",
    "### dataset : accuracy\n",
    "### cleaned_employees.csv : 0.33 - 0.41 after tuning\n",
    "### employee_survey.csv: 0.34 - 0.40 after tuning\n",
    "### processed_features_job_satisfaction.csv: 0.4318 - 0.44 after tuning\n",
    "\n"
   ],
   "id": "5302877cfefa3f63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "dbbd9c55f4142da0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
